{"cells":[{"cell_type":"markdown","id":"cdd466f9-a72a-44df-9e00-6926a97a4923","metadata":{},"source":["![Cartoon of telecom customers](IMG_8811.png)\n"]},{"cell_type":"markdown","id":"dafa483a-e084-4ba8-9236-5c0468364e0d","metadata":{},"source":["The telecommunications (telecom) sector in India is rapidly changing, with more and more telecom businesses being created and many customers deciding to switch between providers. \"Churn\" refers to the process where customers or subscribers stop using a company's services or products. Understanding the factors that influence keeping a customer as a client in predicting churn is crucial for telecom companies to enhance their service quality and customer satisfaction. As the data scientist on this project, you aim to explore the intricate dynamics of customer behavior and demographics in the Indian telecom sector in predicting customer churn, utilizing two comprehensive datasets from four major telecom partners: Airtel, Reliance Jio, Vodafone, and BSNL:\n","\n","- `telecom_demographics.csv` contains information related to Indian customer demographics:\n","\n","| Variable             | Description                                      |\n","|----------------------|--------------------------------------------------|\n","| `customer_id `         | Unique identifier for each customer.             |\n","| `telecom_partner `     | The telecom partner associated with the customer.|\n","| `gender `              | The gender of the customer.                      |\n","| `age `                 | The age of the customer.                         |\n","| `state`                | The Indian state in which the customer is located.|\n","| `city`                 | The city in which the customer is located.       |\n","| `pincode`              | The pincode of the customer's location.          |\n","| `registration_event` | When the customer registered with the telecom partner.|\n","| `num_dependents`      | The number of dependents (e.g., children) the customer has.|\n","| `estimated_salary`     | The customer's estimated salary.                 |\n","\n","- `telecom_usage` contains information about the usage patterns of Indian customers:\n","\n","| Variable   | Description                                                  |\n","|------------|--------------------------------------------------------------|\n","| `customer_id` | Unique identifier for each customer.                         |\n","| `calls_made` | The number of calls made by the customer.                    |\n","| `sms_sent`   | The number of SMS messages sent by the customer.             |\n","| `data_used`  | The amount of data used by the customer.                     |\n","| `churn`    | Binary variable indicating whether the customer has churned or not (1 = churned, 0 = not churned).|\n"]},{"cell_type":"markdown","id":"6ce0a5c5","metadata":{},"source":["# Project Instructions\n","\n","Does Logistic Regression or Random Forest produce a higher accuracy score in predicting telecom churn in India?\n","\n","- Load the two CSV files into separate DataFrames. Merge them into a DataFrame named churn_df. Calculate and print churn rate, and identify the categorical variables in churn_df.\n","- Convert categorical features in churn_df into features_scaled. Perform feature scaling separating the appropriate features and scale them. Define your scaled features and target variable for the churn prediction model.\n","- Split the processed data into training and testing sets giving names of X_train, X_test, y_train, and y_test using an 80-20 split, setting a random state of 42 for reproducibility.\n","- Train Logistic Regression and Random Forest Classifier models, setting a random seed of 42. Store model predictions in logreg_pred and rf_pred.\n","- Assess the models on test data. Assign the model's name with higher accuracy (\"LogisticRegression\" or \"RandomForest\") to higher_accuracy.\n","\n","## Resources \n","Check resources that can help you solve the problem.\n","\n","### LESSONS\n","\n","[Inner join](https://campus.datacamp.com/courses/joining-data-with-pandas/data-merging-basics?ex=1)\n","[Random Forests (RF)](https://campus.datacamp.com/courses/machine-learning-with-tree-based-models-in-python/bagging-and-random-forests?ex=7)\n","[Logistic regression](https://campus.datacamp.com/courses/supervised-learning-with-scikit-learn/fine-tuning-your-model-3?ex=4)\n","\n","### SLIDES\n","\n","[Classification report in scikit-learn](https://campus.datacamp.com/pdf/web/viewer.html?file=https://projector-video-pdf-converter.datacamp.com/28314/chapter3.pdf#page=18)\n","\n","### CHEATSHEETS\n","\n","[Scikit-Learn Cheat Sheet: Python Machine Learning](Scikit-Learn_Cheat_Sheet.pdf)\n"]},{"cell_type":"code","execution_count":470,"id":"95efd3c7-a48a-49c2-9df6-36f078de3b38","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1699920392111,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries and methods/functions\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Start your code here!"},"outputs":[],"source":["# Import libraries and methods/functions\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder \n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":471,"id":"63f25bfa","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>telecom_partner</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>state</th>\n","      <th>city</th>\n","      <th>pincode</th>\n","      <th>registration_event</th>\n","      <th>num_dependents</th>\n","      <th>estimated_salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15169</td>\n","      <td>Airtel</td>\n","      <td>F</td>\n","      <td>26</td>\n","      <td>Himachal Pradesh</td>\n","      <td>Delhi</td>\n","      <td>667173</td>\n","      <td>2020-03-16</td>\n","      <td>4</td>\n","      <td>85979</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>149207</td>\n","      <td>Airtel</td>\n","      <td>F</td>\n","      <td>74</td>\n","      <td>Uttarakhand</td>\n","      <td>Hyderabad</td>\n","      <td>313997</td>\n","      <td>2022-01-16</td>\n","      <td>0</td>\n","      <td>69445</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>148119</td>\n","      <td>Airtel</td>\n","      <td>F</td>\n","      <td>54</td>\n","      <td>Jharkhand</td>\n","      <td>Chennai</td>\n","      <td>549925</td>\n","      <td>2022-01-11</td>\n","      <td>2</td>\n","      <td>75949</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>187288</td>\n","      <td>Reliance Jio</td>\n","      <td>M</td>\n","      <td>29</td>\n","      <td>Bihar</td>\n","      <td>Hyderabad</td>\n","      <td>230636</td>\n","      <td>2022-07-26</td>\n","      <td>3</td>\n","      <td>34272</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14016</td>\n","      <td>Vodafone</td>\n","      <td>M</td>\n","      <td>45</td>\n","      <td>Nagaland</td>\n","      <td>Bangalore</td>\n","      <td>188036</td>\n","      <td>2020-03-11</td>\n","      <td>4</td>\n","      <td>34157</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id telecom_partner gender  age             state       city  \\\n","0        15169          Airtel      F   26  Himachal Pradesh      Delhi   \n","1       149207          Airtel      F   74       Uttarakhand  Hyderabad   \n","2       148119          Airtel      F   54         Jharkhand    Chennai   \n","3       187288    Reliance Jio      M   29             Bihar  Hyderabad   \n","4        14016        Vodafone      M   45          Nagaland  Bangalore   \n","\n","   pincode registration_event  num_dependents  estimated_salary  \n","0   667173         2020-03-16               4             85979  \n","1   313997         2022-01-16               0             69445  \n","2   549925         2022-01-11               2             75949  \n","3   230636         2022-07-26               3             34272  \n","4   188036         2020-03-11               4             34157  "]},"execution_count":471,"metadata":{},"output_type":"execute_result"}],"source":["# Load the two CSV files into separate DataFrames.\n","demographics_df = pd.read_csv(\"telecom_demographics.csv\")\n","demographics_df.head()  "]},{"cell_type":"code","execution_count":472,"id":"7a115fdd","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>calls_made</th>\n","      <th>sms_sent</th>\n","      <th>data_used</th>\n","      <th>churn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15169</td>\n","      <td>75</td>\n","      <td>21</td>\n","      <td>4532</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>149207</td>\n","      <td>35</td>\n","      <td>38</td>\n","      <td>723</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>148119</td>\n","      <td>70</td>\n","      <td>47</td>\n","      <td>4688</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>187288</td>\n","      <td>95</td>\n","      <td>32</td>\n","      <td>10241</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14016</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>5246</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id  calls_made  sms_sent  data_used  churn\n","0        15169          75        21       4532      1\n","1       149207          35        38        723      1\n","2       148119          70        47       4688      1\n","3       187288          95        32      10241      1\n","4        14016          66        23       5246      1"]},"execution_count":472,"metadata":{},"output_type":"execute_result"}],"source":["usage_df = pd.read_csv(\"telecom_usage.csv\")\n","usage_df.head()"]},{"cell_type":"code","execution_count":473,"id":"fd6b8ca9","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>telecom_partner</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>state</th>\n","      <th>city</th>\n","      <th>pincode</th>\n","      <th>registration_event</th>\n","      <th>num_dependents</th>\n","      <th>estimated_salary</th>\n","      <th>calls_made</th>\n","      <th>sms_sent</th>\n","      <th>data_used</th>\n","      <th>churn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15169</td>\n","      <td>Airtel</td>\n","      <td>F</td>\n","      <td>26</td>\n","      <td>Himachal Pradesh</td>\n","      <td>Delhi</td>\n","      <td>667173</td>\n","      <td>2020-03-16</td>\n","      <td>4</td>\n","      <td>85979</td>\n","      <td>75</td>\n","      <td>21</td>\n","      <td>4532</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>149207</td>\n","      <td>Airtel</td>\n","      <td>F</td>\n","      <td>74</td>\n","      <td>Uttarakhand</td>\n","      <td>Hyderabad</td>\n","      <td>313997</td>\n","      <td>2022-01-16</td>\n","      <td>0</td>\n","      <td>69445</td>\n","      <td>35</td>\n","      <td>38</td>\n","      <td>723</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>148119</td>\n","      <td>Airtel</td>\n","      <td>F</td>\n","      <td>54</td>\n","      <td>Jharkhand</td>\n","      <td>Chennai</td>\n","      <td>549925</td>\n","      <td>2022-01-11</td>\n","      <td>2</td>\n","      <td>75949</td>\n","      <td>70</td>\n","      <td>47</td>\n","      <td>4688</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>187288</td>\n","      <td>Reliance Jio</td>\n","      <td>M</td>\n","      <td>29</td>\n","      <td>Bihar</td>\n","      <td>Hyderabad</td>\n","      <td>230636</td>\n","      <td>2022-07-26</td>\n","      <td>3</td>\n","      <td>34272</td>\n","      <td>95</td>\n","      <td>32</td>\n","      <td>10241</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14016</td>\n","      <td>Vodafone</td>\n","      <td>M</td>\n","      <td>45</td>\n","      <td>Nagaland</td>\n","      <td>Bangalore</td>\n","      <td>188036</td>\n","      <td>2020-03-11</td>\n","      <td>4</td>\n","      <td>34157</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>5246</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id telecom_partner gender  age             state       city  \\\n","0        15169          Airtel      F   26  Himachal Pradesh      Delhi   \n","1       149207          Airtel      F   74       Uttarakhand  Hyderabad   \n","2       148119          Airtel      F   54         Jharkhand    Chennai   \n","3       187288    Reliance Jio      M   29             Bihar  Hyderabad   \n","4        14016        Vodafone      M   45          Nagaland  Bangalore   \n","\n","   pincode registration_event  num_dependents  estimated_salary  calls_made  \\\n","0   667173         2020-03-16               4             85979          75   \n","1   313997         2022-01-16               0             69445          35   \n","2   549925         2022-01-11               2             75949          70   \n","3   230636         2022-07-26               3             34272          95   \n","4   188036         2020-03-11               4             34157          66   \n","\n","   sms_sent  data_used  churn  \n","0        21       4532      1  \n","1        38        723      1  \n","2        47       4688      1  \n","3        32      10241      1  \n","4        23       5246      1  "]},"execution_count":473,"metadata":{},"output_type":"execute_result"}],"source":["# Merge them into a DataFrame named churn_df.\n","churn_df = demographics_df.merge(usage_df, on=\"customer_id\")\n","churn_df.head()"]},{"cell_type":"code","execution_count":474,"id":"7918f278","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape:\n"," (6500, 14)\n","Total Observations:  6500\n","Total Churn:  1303\n","churn\n","0    0.799538\n","1    0.200462\n","Name: count, dtype: float64\n"]}],"source":["# Calculate and print churn rate\n","print(\"Shape:\\n\", churn_df.shape)\n","print(\"Total Observations: \", total_samples := churn_df[\"churn\"].count())\n","print(\"Total Churn: \", total_churn := churn_df[\"churn\"].sum())\n","print(churn_rate := churn_df['churn'].value_counts() / len(churn_df))\n"]},{"cell_type":"code","execution_count":475,"id":"3c56e64b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6500 entries, 0 to 6499\n","Data columns (total 14 columns):\n"," #   Column              Non-Null Count  Dtype \n","---  ------              --------------  ----- \n"," 0   customer_id         6500 non-null   int64 \n"," 1   telecom_partner     6500 non-null   object\n"," 2   gender              6500 non-null   object\n"," 3   age                 6500 non-null   int64 \n"," 4   state               6500 non-null   object\n"," 5   city                6500 non-null   object\n"," 6   pincode             6500 non-null   int64 \n"," 7   registration_event  6500 non-null   object\n"," 8   num_dependents      6500 non-null   int64 \n"," 9   estimated_salary    6500 non-null   int64 \n"," 10  calls_made          6500 non-null   int64 \n"," 11  sms_sent            6500 non-null   int64 \n"," 12  data_used           6500 non-null   int64 \n"," 13  churn               6500 non-null   int64 \n","dtypes: int64(9), object(5)\n","memory usage: 711.1+ KB\n","None\n"]}],"source":["# Identify categorical variables\n","print(churn_df.info())\n","categorical_variables = [\n","    \"telecom_partner\",\n","    \"gender\",\n","    \"state\",\n","    \"city\",\n","    \"registration_event\", # used in model answer - I find this one a bit weird\n","]"]},{"cell_type":"code","execution_count":476,"id":"3cb64b3c","metadata":{},"outputs":[],"source":["# Extract label / target\n","target = churn_df['churn']\n","\n","# Drop unwanted columns\n","features = churn_df.drop([\"customer_id\", \"churn\"],axis='columns')"]},{"cell_type":"code","execution_count":477,"id":"cb1e517c","metadata":{},"outputs":[],"source":["# Create an instance of OneHotEncoder\n","encoder = OneHotEncoder(handle_unknown=\"ignore\")\n","\n","# Fit the encoder to the categorical columns\n","encoded = encoder.fit_transform(features[categorical_variables])\n","\n","# Convert the encoded array to a dataframe\n","encoded_df = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out())\n","\n","# Join the encoded dataframe with the original dataframe\n","features_ohe = features.join(encoded_df)\n","\n","# Drop the original categorical columns\n","features_ohe.drop(categorical_variables, axis=1, inplace=True)\n","\n","# Model answer uses this: \n","#features_scaled = pd.get_dummies(features, columns=['telecom_partner', 'gender', 'state', 'city', 'registration_event'])\n"]},{"cell_type":"code","execution_count":478,"id":"3da43562","metadata":{},"outputs":[],"source":["# Splitting the dataset into the Training set and Test set before scaling - not mentioned in the project but is best practice\n","X = features_ohe.values\n","y = target.values"]},{"cell_type":"code","execution_count":479,"id":"8814a13f","metadata":{},"outputs":[],"source":["# Splitting the dataset into the Training set and Test set before scaling - not mentioned in the project but is best practice\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"]},{"cell_type":"code","execution_count":480,"id":"3318d5a9","metadata":{},"outputs":[],"source":["scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n"]},{"cell_type":"code","execution_count":481,"id":"a44c72fe","metadata":{},"outputs":[],"source":["# Train Logistic Regression model\n","logreg = LogisticRegression(random_state=42)\n","logreg.fit(X_train, y_train) \n","\n","logreg_pred = logreg.predict(X_test) "]},{"cell_type":"code","execution_count":482,"id":"a948032d","metadata":{},"outputs":[],"source":["# Random Forest Classifier model\n","rf = RandomForestClassifier(random_state=42)\n","rf.fit(X_train, y_train) \n","\n","rf_pred = rf.predict(X_test) "]},{"cell_type":"code","execution_count":483,"id":"905cf62f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression: \n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.90      0.84      1027\n","           1       0.21      0.10      0.14       273\n","\n","    accuracy                           0.73      1300\n","   macro avg       0.50      0.50      0.49      1300\n","weighted avg       0.67      0.73      0.69      1300\n","\n","\n","Random Forrest: \n","               precision    recall  f1-score   support\n","\n","           0       0.79      1.00      0.88      1027\n","           1       0.00      0.00      0.00       273\n","\n","    accuracy                           0.79      1300\n","   macro avg       0.39      0.50      0.44      1300\n","weighted avg       0.62      0.79      0.70      1300\n","\n"]}],"source":["# Assess the models on test data. First a classification_report\n","print(\"Logistic Regression: \\n\", classification_report(y_test, logreg_pred))\n","print('')\n","print(\"Random Forrest: \\n\", classification_report(y_test, rf_pred))\n","\n"]},{"cell_type":"code","execution_count":484,"id":"9eab424f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression: \n"," [[920 107]\n"," [245  28]]\n","\n","Random Forrest: \n"," [[1026    1]\n"," [ 273    0]]\n"]}],"source":["# And now the confusion_matrix\n","print(\"Logistic Regression: \\n\", confusion_matrix(y_test, logreg_pred))\n","print('')\n","print(\"Random Forrest: \\n\", confusion_matrix(y_test, rf_pred))\n"]},{"cell_type":"code","execution_count":485,"id":"f1dda35e","metadata":{},"outputs":[],"source":["higher_accuracy = \"RandomForest\""]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":5}
