{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "source": [
    "# Spaceship Titanic - Seventh Model\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, \n",
    "the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets \n",
    "orbiting nearby stars.\n",
    "\n",
    "While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic\n",
    "collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000\n",
    "years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n",
    "\n",
    "In this competition your task is to predict whether a passenger was transported to an alternate dimension during the \n",
    "Spaceship Titanic's collision with the spacetime anomaly. To help you make these predictions, you're given a set of personal\n",
    "records recovered from the ship's damaged computer system.\n",
    "\n",
    "## File and Data Field Descriptions\n",
    "\n",
    "### train.csv \n",
    "\n",
    "Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "\n",
    "| Column Name | Description |\n",
    "|------------- |-------------|\n",
    "| `PassengerId` | A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always. |\n",
    "| `HomePlanet` | The planet the passenger departed from, typically their planet of permanent residence. |\n",
    "| `CryoSleep` | Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins. |\n",
    "| `Cabin` | The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard. |\n",
    "| `Destination` | The planet the passenger will be debarking to. |\n",
    "| `Age` | The age of the passenger. |\n",
    "| `VIP` | Whether the passenger has paid for special VIP service during the voyage. |\n",
    "| `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck` | Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities. |\n",
    "| `Name` | The first and last names of the passenger. |\n",
    "| `Transported` | Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict. |\n",
    "\n",
    "### test.csv\n",
    "\n",
    "Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. \n",
    "\n",
    "Your task is to predict the value of Transported for the passengers in this set.\n",
    "    \n",
    "### sample_submission.csv\n",
    "\n",
    "A sample submission file in the correct format.\n",
    "\n",
    "| Column Name | Description |\n",
    "|------------- |-------------|\n",
    "| `PassengerId` | A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always. |\n",
    "| `Transported` | Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='kbinopt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno\n",
    "from collections import Counter\n",
    "\n",
    "# Data visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data - to pandas dataframes\n",
    "\n",
    "test_df = pd.read_csv('./inputs/test.csv')\n",
    "test_idx = test_df['PassengerId']\n",
    "train_df = pd.read_csv('./inputs/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unrequired features & add engineered ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split name into components\n",
    "def split_name(name:str):\n",
    "    if pd.isnull(name): # protect against empty values\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    parts = name.split(' ')\n",
    "    first = parts[0]\n",
    "    last = parts[-1]\n",
    "    return (first, last)\n",
    "\n",
    "# split cabin into components\n",
    "def split_cabin(name:str):\n",
    "    if pd.isnull(name): # protect against empty values\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    parts = name.split('/')\n",
    "    deck = parts[0]\n",
    "    side = parts[-1]\n",
    "    number = ' '.join(parts[1:-1])\n",
    "    return (deck, number, side)\n",
    "\n",
    "# This function will drop and add required features\n",
    "def feature_manipulation(d : pd.DataFrame) -> pd.DataFrame:\n",
    "    # print the shape of the provided dataframe\n",
    "    print(\"Before: \", d.shape)\n",
    "    # Clone the provided dataframe\n",
    "    df = d.copy()\n",
    "\n",
    "    _, df['Name'] = zip(*df['Name'].map(split_name))\n",
    "    \n",
    "    # Location\n",
    "    df['Deck'], _, df['Side'] = zip(*df['Cabin'].map(split_cabin))\n",
    "    df['DeckSide'] = df['Deck'] + df['Side'] # Combine Deck and Side\n",
    "\n",
    "    # Group related columns\n",
    "    df['Group'] = df['PassengerId'].map(lambda x: x.split('_')[0])\n",
    "    df['GroupSize'] = df['Group'].map(df['Group'].value_counts())\n",
    "    \n",
    "    print(\"After: \", df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (8693, 14)\n",
      "After:  (8693, 19)\n"
     ]
    }
   ],
   "source": [
    "train_df = feature_manipulation(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (4277, 13)\n",
      "After:  (4277, 18)\n"
     ]
    }
   ],
   "source": [
    "test_df = feature_manipulation(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "      <th>DeckSide</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>BP</td>\n",
       "      <td>0001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>FS</td>\n",
       "      <td>0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>AS</td>\n",
       "      <td>0003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>AS</td>\n",
       "      <td>0003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>FS</td>\n",
       "      <td>0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck         Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0        Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0       Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Santantines   \n",
       "\n",
       "   Transported Deck Side DeckSide Group  GroupSize  \n",
       "0        False    B    P       BP  0001          1  \n",
       "1         True    F    S       FS  0002          1  \n",
       "2        False    A    S       AS  0003          2  \n",
       "3        False    A    S       AS  0003          2  \n",
       "4         True    F    S       FS  0004          1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "      <th>DeckSide</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carsoning</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>GS</td>\n",
       "      <td>0013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Peckers</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>FS</td>\n",
       "      <td>0018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unhearfus</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>CS</td>\n",
       "      <td>0019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Caltilter</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>CS</td>\n",
       "      <td>0021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Harperez</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>FS</td>\n",
       "      <td>0023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck       Name Deck Side  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0  Carsoning    G    S   \n",
       "1          0.0        9.0           0.0  2823.0     0.0    Peckers    F    S   \n",
       "2          0.0        0.0           0.0     0.0     0.0  Unhearfus    C    S   \n",
       "3          0.0     6652.0           0.0   181.0   585.0  Caltilter    C    S   \n",
       "4         10.0        0.0         635.0     0.0     0.0   Harperez    F    S   \n",
       "\n",
       "  DeckSide Group  GroupSize  \n",
       "0       GS  0013          1  \n",
       "1       FS  0018          1  \n",
       "2       CS  0019          1  \n",
       "3       CS  0021          1  \n",
       "4       FS  0023          1  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Data\n",
    "\n",
    "In the first model we had a complicated approach - here we will just use the median for numeric and mode for non-numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to print missing data\n",
    "def print_missing(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Train Missing': train.isnull().sum(),\n",
    "        'Test Missing': test.isnull().sum()\n",
    "    }).sort_values(by='Train Missing', ascending=False)\n",
    "\n",
    "    print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Train Missing  Test Missing\n",
      "CryoSleep               217          93.0\n",
      "ShoppingMall            208          98.0\n",
      "VIP                     203          93.0\n",
      "HomePlanet              201          87.0\n",
      "Name                    200          94.0\n",
      "Cabin                   199         100.0\n",
      "Deck                    199         100.0\n",
      "DeckSide                199         100.0\n",
      "Side                    199         100.0\n",
      "VRDeck                  188          80.0\n",
      "FoodCourt               183         106.0\n",
      "Spa                     183         101.0\n",
      "Destination             182          92.0\n",
      "RoomService             181          82.0\n",
      "Age                     179          91.0\n",
      "GroupSize                 0           0.0\n",
      "PassengerId               0           0.0\n",
      "Group                     0           0.0\n",
      "Transported               0           NaN\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data before imputing\n",
    "print_missing(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to replace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_median(df, features):\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].fillna(df[feature].median())\n",
    "    return df\n",
    "\n",
    "def fill_with_mode(df, features):\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].fillna(df[feature].mode()[0])\n",
    "    return df\n",
    "\n",
    "def fill_with_mean(df, features):\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].fillna(df[feature].mean())\n",
    "    return df\n",
    "\n",
    "# Here we provide a list of other_features - if a row has a nan in a feature we will fill it with the mean of the other_features in its row \n",
    "def fill_with_mean_of_other_features(df, features, other_features):\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].fillna(df[other_features].dropna().mean(axis=1))\n",
    "    return df\n",
    "\n",
    "def fill_with_constant(df, features, constant):\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].fillna(constant)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply simple rules for empty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_empty_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "   \n",
    "    # fill in missing values with a constant\n",
    "    df = fill_with_constant(df, ['VIP'], False)\n",
    "    df = fill_with_constant(df, ['Name', 'Cabin', 'Deck', 'Side', 'DeckSide', 'HomePlanet', 'Destination'], 'Unknown')\n",
    "\n",
    "    # Fill numerics with median\n",
    "    df = fill_with_median(df, ['Age'])\n",
    "    \n",
    "    # Fill with average of other spend features\n",
    "    spend_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    df = fill_with_mean_of_other_features(df, spend_features, spend_features)\n",
    "    df = fill_with_constant(df, spend_features, 0)\n",
    "\n",
    "    # Have a sensible default so leave this as is\n",
    "    # for the provided dataframe set CryoSleep to False if TotalSpend is greater than 0\n",
    "    UnknownCryoSpender = (df[\"CryoSleep\"].isnull() | df[\"CryoSleep\"].isna()) & (df[spend_features].dropna().sum(axis=1) > 0)\n",
    "    df.loc[UnknownCryoSpender, 'CryoSleep'] = False\n",
    "    df['CryoSleep'] = df['CryoSleep'].fillna('Unknown')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = handle_empty_data(train_df)\n",
    "test_df = handle_empty_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Train Missing  Test Missing\n",
      "Age                       0           0.0\n",
      "Name                      0           0.0\n",
      "VIP                       0           0.0\n",
      "Transported               0           NaN\n",
      "Spa                       0           0.0\n",
      "Side                      0           0.0\n",
      "ShoppingMall              0           0.0\n",
      "RoomService               0           0.0\n",
      "PassengerId               0           0.0\n",
      "HomePlanet                0           0.0\n",
      "Cabin                     0           0.0\n",
      "GroupSize                 0           0.0\n",
      "Group                     0           0.0\n",
      "FoodCourt                 0           0.0\n",
      "Destination               0           0.0\n",
      "DeckSide                  0           0.0\n",
      "Deck                      0           0.0\n",
      "CryoSleep                 0           0.0\n",
      "VRDeck                    0           0.0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data after imputing\n",
    "print_missing(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "      <th>DeckSide</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>BP</td>\n",
       "      <td>0001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>FS</td>\n",
       "      <td>0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>AS</td>\n",
       "      <td>0003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>AS</td>\n",
       "      <td>0003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>FS</td>\n",
       "      <td>0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck         Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0        Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0       Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Santantines   \n",
       "\n",
       "   Transported Deck Side DeckSide Group  GroupSize  \n",
       "0        False    B    P       BP  0001          1  \n",
       "1         True    F    S       FS  0002          1  \n",
       "2        False    A    S       AS  0003          2  \n",
       "3        False    A    S       AS  0003          2  \n",
       "4         True    F    S       FS  0004          1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the training data after the changes to remove empty data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "      <th>DeckSide</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carsoning</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>GS</td>\n",
       "      <td>0013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Peckers</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>FS</td>\n",
       "      <td>0018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unhearfus</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>CS</td>\n",
       "      <td>0019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Caltilter</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>CS</td>\n",
       "      <td>0021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Harperez</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>FS</td>\n",
       "      <td>0023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck       Name Deck Side  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0  Carsoning    G    S   \n",
       "1          0.0        9.0           0.0  2823.0     0.0    Peckers    F    S   \n",
       "2          0.0        0.0           0.0     0.0     0.0  Unhearfus    C    S   \n",
       "3          0.0     6652.0           0.0   181.0   585.0  Caltilter    C    S   \n",
       "4         10.0        0.0         635.0     0.0     0.0   Harperez    F    S   \n",
       "\n",
       "  DeckSide Group  GroupSize  \n",
       "0       GS  0013          1  \n",
       "1       FS  0018          1  \n",
       "2       CS  0019          1  \n",
       "3       CS  0021          1  \n",
       "4       FS  0023          1  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the test data\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8693, 19)\n",
      "Test: (4277, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HomePlanet</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CryoSleep</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIP</th>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoomService</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FoodCourt</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShoppingMall</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spa</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRDeck</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transported</th>\n",
       "      <td>bool</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Side</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeckSide</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroupSize</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Train     Test\n",
       "PassengerId    object   object\n",
       "HomePlanet     object   object\n",
       "CryoSleep      object   object\n",
       "Cabin          object   object\n",
       "Destination    object   object\n",
       "Age           float64  float64\n",
       "VIP              bool     bool\n",
       "RoomService   float64  float64\n",
       "FoodCourt     float64  float64\n",
       "ShoppingMall  float64  float64\n",
       "Spa           float64  float64\n",
       "VRDeck        float64  float64\n",
       "Name           object   object\n",
       "Transported      bool      NaN\n",
       "Deck           object   object\n",
       "Side           object   object\n",
       "DeckSide       object   object\n",
       "Group          object   object\n",
       "GroupSize       int64    int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shapes:\n",
    "\n",
    "print(f'Train: {train_df.shape}')\n",
    "print(f'Test: {test_df.shape}')\n",
    "\n",
    "# Check the train and test column data types side by side\n",
    "pd.concat([train_df.dtypes, test_df.dtypes], axis=1, keys=['Train', 'Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Unrequired columns\n",
    "\n",
    "We can now drop these columns:\n",
    "\n",
    "- Cabin\n",
    "- TotalSpend\n",
    "- PassengerId - may do this one last so we have the key\n",
    "\n",
    "And to simplify for now lets also remove\n",
    "- Name\n",
    "- Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that are not required\n",
    "def drop_unrequired_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    columns_to_drop = [\n",
    "        'Cabin',\n",
    "        'Name',\n",
    "        'DeckSide'\n",
    "    ]\n",
    "    df.drop(columns_to_drop, axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "train_df = drop_unrequired_columns(train_df)\n",
    "test_df = drop_unrequired_columns(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for training\n",
    "\n",
    "- Log/Bin the numeric data\n",
    "- OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet\n",
      "CryoSleep\n",
      "Destination\n",
      "Deck\n",
      "Side\n"
     ]
    }
   ],
   "source": [
    "# There are some cases where we have used 'Unknown' in boolean columns that have True and False otherwise that led to an error\n",
    "# complaining about a mix of str and bool so we need to convert the columns to str\n",
    "\n",
    "# print all columns where the value is 'Unknown'\n",
    "for column in train_df.columns:\n",
    "    if 'Unknown' in train_df[column].unique():\n",
    "        print(column)\n",
    "        train_df[column] = train_df[column].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>0001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>0003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>0003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Destination   Age    VIP  RoomService  \\\n",
       "0     0001_01     Europa     False  TRAPPIST-1e  39.0  False          0.0   \n",
       "1     0002_01      Earth     False  TRAPPIST-1e  24.0  False        109.0   \n",
       "2     0003_01     Europa     False  TRAPPIST-1e  58.0   True         43.0   \n",
       "3     0003_02     Europa     False  TRAPPIST-1e  33.0  False          0.0   \n",
       "4     0004_01      Earth     False  TRAPPIST-1e  16.0  False        303.0   \n",
       "\n",
       "   FoodCourt  ShoppingMall     Spa  VRDeck  Transported Deck Side Group  \\\n",
       "0        0.0           0.0     0.0     0.0        False    B    P  0001   \n",
       "1        9.0          25.0   549.0    44.0         True    F    S  0002   \n",
       "2     3576.0           0.0  6715.0    49.0        False    A    S  0003   \n",
       "3     1283.0         371.0  3329.0   193.0        False    A    S  0003   \n",
       "4       70.0         151.0   565.0     2.0         True    F    S  0004   \n",
       "\n",
       "   GroupSize  \n",
       "0          1  \n",
       "1          1  \n",
       "2          2  \n",
       "3          2  \n",
       "4          1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what data looks like before pipeline\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessor\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define pipelines for the features where we wish to bin and OHE\n",
    "def preprocessor(n_bins: int, strategy='quantile', scaling_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], categorical_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']):\n",
    "    scaling_pipeline = Pipeline([\n",
    "        ('scale', RobustScaler()),\n",
    "    ])\n",
    "\n",
    "    age_pipeline = Pipeline([\n",
    "        ('scale', RobustScaler())\n",
    "    ])\n",
    "    if n_bins > 0:\n",
    "        age_pipeline = Pipeline([\n",
    "            ('binning', KBinsDiscretizer(n_bins=n_bins, encode='onehot-dense', strategy=strategy))\n",
    "        ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('onehot', OneHotEncoder())\n",
    "    ])\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('category', categorical_pipeline, categorical_features),\n",
    "            ('spending', scaling_pipeline, scaling_features),\n",
    "            ('age', age_pipeline, ['Age'])\n",
    "        ],\n",
    "        remainder='passthrough'  # This leaves the rest of the columns untouched\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.pop('Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = train_df.pop('PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to attempt the modelling\n",
    "\n",
    "## Split the data to create a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to score models\n",
    "def score_model(classifier, X_train, X_val, y_train, y_val):\n",
    "    # Fit the model\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test data\n",
    "    y_pred = classifier.predict(X_val)\n",
    "\n",
    "    # Create a confusion matrix\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    scores = cross_val_score(classifier, X_train, y_train, cv = 10)\n",
    "\n",
    "    return { \n",
    "            'confusion_matrix': cm,\n",
    "            'accuracy': acc,\n",
    "            'kfold-cv': scores.mean()\n",
    "        }\n",
    "\n",
    "def run_classifiers(classifiers: dict, X_train, X_test, y_train, y_val) -> dict:\n",
    "    results = {}\n",
    "    for name, classifier in classifiers.items():\n",
    "        results[name] = score_model(classifier, X_train, X_test, y_train, y_val)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "classifiers = {\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the split data & Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "bins_to_try = [0]\n",
    "for x in range(2, 20):\n",
    "    bins_to_try.append(x)\n",
    "for n_bins in bins_to_try:\n",
    "    prep = preprocessor(n_bins)\n",
    "    results[f'quan_{n_bins}'] = list(run_classifiers(classifiers, prep.fit_transform(X_train), prep.transform(X_val), y_train, y_val).values())[0]\n",
    "    prep = preprocessor(n_bins, strategy='uniform')\n",
    "    results[f'uni_{n_bins}'] = list(run_classifiers(classifiers, prep.fit_transform(X_train), prep.transform(X_val), y_train, y_val).values())[0]\n",
    "    prep = preprocessor(n_bins, strategy='kmeans')\n",
    "    results[f'km_{n_bins}'] = list(run_classifiers(classifiers, prep.fit_transform(X_train), prep.transform(X_val), y_train, y_val).values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>kfold-cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uni_8</th>\n",
       "      <td>[[855, 222], [215, 882]]</td>\n",
       "      <td>0.798988</td>\n",
       "      <td>0.804109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_11</th>\n",
       "      <td>[[861, 216], [218, 879]]</td>\n",
       "      <td>0.800368</td>\n",
       "      <td>0.803955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_18</th>\n",
       "      <td>[[866, 211], [220, 877]]</td>\n",
       "      <td>0.801748</td>\n",
       "      <td>0.802423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_6</th>\n",
       "      <td>[[853, 224], [211, 886]]</td>\n",
       "      <td>0.799908</td>\n",
       "      <td>0.802269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_11</th>\n",
       "      <td>[[859, 218], [204, 893]]</td>\n",
       "      <td>0.805888</td>\n",
       "      <td>0.801962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_18</th>\n",
       "      <td>[[863, 214], [210, 887]]</td>\n",
       "      <td>0.804968</td>\n",
       "      <td>0.801962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_16</th>\n",
       "      <td>[[851, 226], [205, 892]]</td>\n",
       "      <td>0.801748</td>\n",
       "      <td>0.801809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_14</th>\n",
       "      <td>[[869, 208], [204, 893]]</td>\n",
       "      <td>0.810488</td>\n",
       "      <td>0.801347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_10</th>\n",
       "      <td>[[864, 213], [204, 893]]</td>\n",
       "      <td>0.808188</td>\n",
       "      <td>0.801195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_12</th>\n",
       "      <td>[[853, 224], [221, 876]]</td>\n",
       "      <td>0.795308</td>\n",
       "      <td>0.801194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_5</th>\n",
       "      <td>[[855, 222], [208, 889]]</td>\n",
       "      <td>0.802208</td>\n",
       "      <td>0.80089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_12</th>\n",
       "      <td>[[856, 221], [220, 877]]</td>\n",
       "      <td>0.797148</td>\n",
       "      <td>0.800889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_8</th>\n",
       "      <td>[[862, 215], [217, 880]]</td>\n",
       "      <td>0.801288</td>\n",
       "      <td>0.800582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_9</th>\n",
       "      <td>[[855, 222], [217, 880]]</td>\n",
       "      <td>0.798068</td>\n",
       "      <td>0.80058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_3</th>\n",
       "      <td>[[857, 220], [213, 884]]</td>\n",
       "      <td>0.800828</td>\n",
       "      <td>0.800275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_7</th>\n",
       "      <td>[[845, 232], [205, 892]]</td>\n",
       "      <td>0.798988</td>\n",
       "      <td>0.800122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_11</th>\n",
       "      <td>[[859, 218], [212, 885]]</td>\n",
       "      <td>0.802208</td>\n",
       "      <td>0.800122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_4</th>\n",
       "      <td>[[843, 234], [210, 887]]</td>\n",
       "      <td>0.795768</td>\n",
       "      <td>0.800121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_10</th>\n",
       "      <td>[[864, 213], [202, 895]]</td>\n",
       "      <td>0.809108</td>\n",
       "      <td>0.80012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_5</th>\n",
       "      <td>[[836, 241], [212, 885]]</td>\n",
       "      <td>0.791628</td>\n",
       "      <td>0.79997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_3</th>\n",
       "      <td>[[846, 231], [213, 884]]</td>\n",
       "      <td>0.795768</td>\n",
       "      <td>0.799967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_2</th>\n",
       "      <td>[[854, 223], [211, 886]]</td>\n",
       "      <td>0.800368</td>\n",
       "      <td>0.799967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_17</th>\n",
       "      <td>[[854, 223], [208, 889]]</td>\n",
       "      <td>0.801748</td>\n",
       "      <td>0.799506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_6</th>\n",
       "      <td>[[865, 212], [202, 895]]</td>\n",
       "      <td>0.809568</td>\n",
       "      <td>0.799354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_8</th>\n",
       "      <td>[[860, 217], [199, 898]]</td>\n",
       "      <td>0.808648</td>\n",
       "      <td>0.799353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_13</th>\n",
       "      <td>[[857, 220], [201, 896]]</td>\n",
       "      <td>0.806348</td>\n",
       "      <td>0.799047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_14</th>\n",
       "      <td>[[860, 217], [208, 889]]</td>\n",
       "      <td>0.804508</td>\n",
       "      <td>0.798894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_14</th>\n",
       "      <td>[[851, 226], [204, 893]]</td>\n",
       "      <td>0.802208</td>\n",
       "      <td>0.798893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_19</th>\n",
       "      <td>[[842, 235], [210, 887]]</td>\n",
       "      <td>0.795308</td>\n",
       "      <td>0.798741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_19</th>\n",
       "      <td>[[842, 235], [210, 887]]</td>\n",
       "      <td>0.795308</td>\n",
       "      <td>0.798741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_15</th>\n",
       "      <td>[[856, 221], [215, 882]]</td>\n",
       "      <td>0.799448</td>\n",
       "      <td>0.79874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_9</th>\n",
       "      <td>[[848, 229], [211, 886]]</td>\n",
       "      <td>0.797608</td>\n",
       "      <td>0.79874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_12</th>\n",
       "      <td>[[860, 217], [205, 892]]</td>\n",
       "      <td>0.805888</td>\n",
       "      <td>0.798433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_17</th>\n",
       "      <td>[[849, 228], [204, 893]]</td>\n",
       "      <td>0.801288</td>\n",
       "      <td>0.798433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_7</th>\n",
       "      <td>[[858, 219], [209, 888]]</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.79828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_15</th>\n",
       "      <td>[[864, 213], [208, 889]]</td>\n",
       "      <td>0.806348</td>\n",
       "      <td>0.798279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_19</th>\n",
       "      <td>[[864, 213], [209, 888]]</td>\n",
       "      <td>0.805888</td>\n",
       "      <td>0.797975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_0</th>\n",
       "      <td>[[857, 220], [208, 889]]</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.79782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_0</th>\n",
       "      <td>[[857, 220], [208, 889]]</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.79782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_0</th>\n",
       "      <td>[[857, 220], [208, 889]]</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.79782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_4</th>\n",
       "      <td>[[852, 225], [210, 887]]</td>\n",
       "      <td>0.799908</td>\n",
       "      <td>0.797668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_9</th>\n",
       "      <td>[[853, 224], [216, 881]]</td>\n",
       "      <td>0.797608</td>\n",
       "      <td>0.797666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_17</th>\n",
       "      <td>[[853, 224], [211, 886]]</td>\n",
       "      <td>0.799908</td>\n",
       "      <td>0.797513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_3</th>\n",
       "      <td>[[853, 224], [218, 879]]</td>\n",
       "      <td>0.796688</td>\n",
       "      <td>0.797053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_18</th>\n",
       "      <td>[[865, 212], [208, 889]]</td>\n",
       "      <td>0.806808</td>\n",
       "      <td>0.7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_5</th>\n",
       "      <td>[[853, 224], [204, 893]]</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.796747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_15</th>\n",
       "      <td>[[868, 209], [216, 881]]</td>\n",
       "      <td>0.804508</td>\n",
       "      <td>0.796745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_2</th>\n",
       "      <td>[[843, 234], [214, 883]]</td>\n",
       "      <td>0.793928</td>\n",
       "      <td>0.79644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_16</th>\n",
       "      <td>[[853, 224], [212, 885]]</td>\n",
       "      <td>0.799448</td>\n",
       "      <td>0.79644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_10</th>\n",
       "      <td>[[863, 214], [196, 901]]</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.796287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_6</th>\n",
       "      <td>[[853, 224], [208, 889]]</td>\n",
       "      <td>0.801288</td>\n",
       "      <td>0.796287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_7</th>\n",
       "      <td>[[849, 228], [209, 888]]</td>\n",
       "      <td>0.798988</td>\n",
       "      <td>0.796131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_4</th>\n",
       "      <td>[[843, 234], [208, 889]]</td>\n",
       "      <td>0.796688</td>\n",
       "      <td>0.795672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_13</th>\n",
       "      <td>[[860, 217], [207, 890]]</td>\n",
       "      <td>0.804968</td>\n",
       "      <td>0.795671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_16</th>\n",
       "      <td>[[852, 225], [204, 893]]</td>\n",
       "      <td>0.802668</td>\n",
       "      <td>0.795366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_2</th>\n",
       "      <td>[[861, 216], [211, 886]]</td>\n",
       "      <td>0.803588</td>\n",
       "      <td>0.795213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan_13</th>\n",
       "      <td>[[853, 224], [221, 876]]</td>\n",
       "      <td>0.795308</td>\n",
       "      <td>0.79506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 confusion_matrix  accuracy  kfold-cv\n",
       "uni_8    [[855, 222], [215, 882]]  0.798988  0.804109\n",
       "uni_11   [[861, 216], [218, 879]]  0.800368  0.803955\n",
       "km_18    [[866, 211], [220, 877]]  0.801748  0.802423\n",
       "quan_6   [[853, 224], [211, 886]]  0.799908  0.802269\n",
       "km_11    [[859, 218], [204, 893]]  0.805888  0.801962\n",
       "uni_18   [[863, 214], [210, 887]]  0.804968  0.801962\n",
       "km_16    [[851, 226], [205, 892]]  0.801748  0.801809\n",
       "uni_14   [[869, 208], [204, 893]]  0.810488  0.801347\n",
       "km_10    [[864, 213], [204, 893]]  0.808188  0.801195\n",
       "km_12    [[853, 224], [221, 876]]  0.795308  0.801194\n",
       "km_5     [[855, 222], [208, 889]]  0.802208   0.80089\n",
       "uni_12   [[856, 221], [220, 877]]  0.797148  0.800889\n",
       "quan_8   [[862, 215], [217, 880]]  0.801288  0.800582\n",
       "uni_9    [[855, 222], [217, 880]]  0.798068   0.80058\n",
       "km_3     [[857, 220], [213, 884]]  0.800828  0.800275\n",
       "uni_7    [[845, 232], [205, 892]]  0.798988  0.800122\n",
       "quan_11  [[859, 218], [212, 885]]  0.802208  0.800122\n",
       "uni_4    [[843, 234], [210, 887]]  0.795768  0.800121\n",
       "quan_10  [[864, 213], [202, 895]]  0.809108   0.80012\n",
       "uni_5    [[836, 241], [212, 885]]  0.791628   0.79997\n",
       "uni_3    [[846, 231], [213, 884]]  0.795768  0.799967\n",
       "km_2     [[854, 223], [211, 886]]  0.800368  0.799967\n",
       "uni_17   [[854, 223], [208, 889]]  0.801748  0.799506\n",
       "uni_6    [[865, 212], [202, 895]]  0.809568  0.799354\n",
       "km_8     [[860, 217], [199, 898]]  0.808648  0.799353\n",
       "km_13    [[857, 220], [201, 896]]  0.806348  0.799047\n",
       "km_14    [[860, 217], [208, 889]]  0.804508  0.798894\n",
       "quan_14  [[851, 226], [204, 893]]  0.802208  0.798893\n",
       "km_19    [[842, 235], [210, 887]]  0.795308  0.798741\n",
       "uni_19   [[842, 235], [210, 887]]  0.795308  0.798741\n",
       "km_15    [[856, 221], [215, 882]]  0.799448   0.79874\n",
       "quan_9   [[848, 229], [211, 886]]  0.797608   0.79874\n",
       "quan_12  [[860, 217], [205, 892]]  0.805888  0.798433\n",
       "quan_17  [[849, 228], [204, 893]]  0.801288  0.798433\n",
       "quan_7   [[858, 219], [209, 888]]  0.803128   0.79828\n",
       "quan_15  [[864, 213], [208, 889]]  0.806348  0.798279\n",
       "quan_19  [[864, 213], [209, 888]]  0.805888  0.797975\n",
       "quan_0   [[857, 220], [208, 889]]  0.803128   0.79782\n",
       "uni_0    [[857, 220], [208, 889]]  0.803128   0.79782\n",
       "km_0     [[857, 220], [208, 889]]  0.803128   0.79782\n",
       "km_4     [[852, 225], [210, 887]]  0.799908  0.797668\n",
       "km_9     [[853, 224], [216, 881]]  0.797608  0.797666\n",
       "km_17    [[853, 224], [211, 886]]  0.799908  0.797513\n",
       "quan_3   [[853, 224], [218, 879]]  0.796688  0.797053\n",
       "quan_18  [[865, 212], [208, 889]]  0.806808    0.7969\n",
       "quan_5   [[853, 224], [204, 893]]  0.803128  0.796747\n",
       "uni_15   [[868, 209], [216, 881]]  0.804508  0.796745\n",
       "uni_2    [[843, 234], [214, 883]]  0.793928   0.79644\n",
       "quan_16  [[853, 224], [212, 885]]  0.799448   0.79644\n",
       "uni_10   [[863, 214], [196, 901]]  0.811408  0.796287\n",
       "km_6     [[853, 224], [208, 889]]  0.801288  0.796287\n",
       "km_7     [[849, 228], [209, 888]]  0.798988  0.796131\n",
       "quan_4   [[843, 234], [208, 889]]  0.796688  0.795672\n",
       "uni_13   [[860, 217], [207, 890]]  0.804968  0.795671\n",
       "uni_16   [[852, 225], [204, 893]]  0.802668  0.795366\n",
       "quan_2   [[861, 216], [211, 886]]  0.803588  0.795213\n",
       "quan_13  [[853, 224], [221, 876]]  0.795308   0.79506"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert results to a dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.sort_values(by='kfold-cv', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041092985779311"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best mean of kfold-cv plus accuracy\n",
    "results_df['kfold-cv'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the two best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune a model using GridSearchCV\n",
    "def tune_model(classifier, param_grid):\n",
    "    print(f'\\n\\nTuning {classifier.__class__.__name__}...')\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=10, n_jobs = -1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    score = score_model(best_estimator, X_train, X_val, y_train, y_val)\n",
    "\n",
    "    print(f'Best SVC Accuracy: { score[\"accuracy\"] }')\n",
    "    print(f'Best SVC KFold CV: { score[\"kfold-cv\"] }')\n",
    "    f1 = f1_score(y_val, best_estimator.predict(X_val))\n",
    "    # and finally the f1 score\n",
    "    print(f'F1 Score: {f1}')\n",
    "\n",
    "    return (grid_search.best_params_, best_estimator, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tuning XGBClassifier...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 270 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n270 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1500, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/sklearn.py\", line 521, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/sklearn.py\", line 958, in _create_dmatrix\n    return QuantileDMatrix(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 1529, in __init__\n    self._init(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 1588, in _init\n    it.reraise()\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 576, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 557, in _handle_exception\n    return fn()\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 641, in <lambda>\n    return self._handle_exception(lambda: self.next(input_data), 0)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/data.py\", line 1280, in next\n    input_data(**self.kwargs)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 624, in input_data\n    new, cat_codes, feature_names, feature_types = _proxy_transform(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/data.py\", line 1315, in _proxy_transform\n    arr, feature_names, feature_types = _transform_pandas_df(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/data.py\", line 490, in _transform_pandas_df\n    _invalid_dataframe_dtype(data)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/data.py\", line 308, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:HomePlanet: object, CryoSleep: object, Destination: object, Deck: object, Side: object, Group: object\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tuning_results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXGBClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_metric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_label_encoder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     12\u001b[0m     tune_model(\n\u001b[1;32m     13\u001b[0m         RandomForestClassifier(), \n\u001b[1;32m     14\u001b[0m         param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m         }\n\u001b[1;32m     19\u001b[0m     ),\n\u001b[1;32m     20\u001b[0m     tune_model(\n\u001b[1;32m     21\u001b[0m         CatBoostClassifier(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     22\u001b[0m         param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.001\u001b[39m],\n\u001b[1;32m     26\u001b[0m         }\n\u001b[1;32m     27\u001b[0m     ),\n\u001b[1;32m     28\u001b[0m     tune_model(\n\u001b[1;32m     29\u001b[0m         LGBMClassifier(),\n\u001b[1;32m     30\u001b[0m         param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.001\u001b[39m],\n\u001b[1;32m     34\u001b[0m         }\n\u001b[1;32m     35\u001b[0m     ),\n\u001b[1;32m     36\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[94], line 5\u001b[0m, in \u001b[0;36mtune_model\u001b[0;34m(classifier, param_grid)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTuning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassifier\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(classifier, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m best_estimator \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m      7\u001b[0m score \u001b[38;5;241m=\u001b[39m score_model(best_estimator, X_train, X_val, y_train, y_val)\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 270 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n270 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1500, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/sklearn.py\", line 521, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/sklearn.py\", line 958, in _create_dmatrix\n    return QuantileDMatrix(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 1529, in __init__\n    self._init(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 1588, in _init\n    it.reraise()\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 576, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 557, in _handle_exception\n    return fn()\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 641, in <lambda>\n    return self._handle_exception(lambda: self.next(input_data), 0)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/data.py\", line 1280, in next\n    input_data(**self.kwargs)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/core.py\", line 624, in input_data\n    new, cat_codes, feature_names, feature_types = _proxy_transform(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/data.py\", line 1315, in _proxy_transform\n    arr, feature_names, feature_types = _transform_pandas_df(\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/data.py\", line 490, in _transform_pandas_df\n    _invalid_dataframe_dtype(data)\n  File \"/Users/n18576/source/edoatley/ml/.venv/lib/python3.9/site-packages/xgboost/data.py\", line 308, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:HomePlanet: object, CryoSleep: object, Destination: object, Deck: object, Side: object, Group: object\n"
     ]
    }
   ],
   "source": [
    "tuning_results = [\n",
    "    tune_model(\n",
    "        XGBClassifier(),\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.1, 0.01, 0.001],\n",
    "            'eval_metric': ['logloss'], \n",
    "            'use_label_encoder': [False]\n",
    "        }, \n",
    "    ),\n",
    "    tune_model(\n",
    "        RandomForestClassifier(), \n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }\n",
    "    ),\n",
    "    tune_model(\n",
    "        CatBoostClassifier(verbose=0),\n",
    "        param_grid = {\n",
    "            'iterations': [100, 200, 300],\n",
    "            'depth': [3, 4, 5],\n",
    "            'learning_rate': [0.1, 0.01, 0.001],\n",
    "        }\n",
    "    ),\n",
    "    tune_model(\n",
    "        LGBMClassifier(),\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.1, 0.01, 0.001],\n",
    "        }\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the F1 Scores for the different models\n",
    "for result in tuning_results:\n",
    "    print(f'F1 Score for {result[1].__class__}: {result[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = max(tuning_results, key=lambda x: x[2])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission\n",
    "\n",
    "Now we can predict the test set and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any Boolean columns with Unknown to String type\n",
    "for column in test_df.columns:\n",
    "    if 'Unknown' in test_df[column].unique():\n",
    "        print(column)\n",
    "        test_df[column] = test_df[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape\n",
    "\n",
    "print(f'Test: {test_df.shape}')\n",
    "\n",
    "# Print the first 5 rows:\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the passenger IDs for submission and remove from the data as not useful predictors\n",
    "idx_test = test_df.pop('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process test set\n",
    "X_test = preprocessor.transform(test_df) # sparse to dense array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set\n",
    "y_pred = best_result.predict(X_test).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the submission DataFrame\n",
    "submission = pd.DataFrame({'PassengerId': idx_test, 'Transported': y_pred})\n",
    "submission.to_csv(f'submissions/{model}-submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
