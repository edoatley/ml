{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, \n",
    "the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets \n",
    "orbiting nearby stars.\n",
    "\n",
    "While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic\n",
    "collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000\n",
    "years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n",
    "\n",
    "In this competition your task is to predict whether a passenger was transported to an alternate dimension during the \n",
    "Spaceship Titanic's collision with the spacetime anomaly. To help you make these predictions, you're given a set of personal\n",
    "records recovered from the ship's damaged computer system.\n",
    "\n",
    "## File and Data Field Descriptions\n",
    "\n",
    "### train.csv \n",
    "\n",
    "Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "\n",
    "| Column Name | Description |\n",
    "|------------- |-------------|\n",
    "| `PassengerId` | A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always. |\n",
    "| `HomePlanet` | The planet the passenger departed from, typically their planet of permanent residence. |\n",
    "| `CryoSleep` | Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins. |\n",
    "| `Cabin` | The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard. |\n",
    "| `Destination` | The planet the passenger will be debarking to. |\n",
    "| `Age` | The age of the passenger. |\n",
    "| `VIP` | Whether the passenger has paid for special VIP service during the voyage. |\n",
    "| `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck` | Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities. |\n",
    "| `Name` | The first and last names of the passenger. |\n",
    "| `Transported` | Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict. |\n",
    "\n",
    "### test.csv\n",
    "\n",
    "Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. \n",
    "\n",
    "Your task is to predict the value of Transported for the passengers in this set.\n",
    "    \n",
    "### sample_submission.csv\n",
    "\n",
    "A sample submission file in the correct format.\n",
    "\n",
    "| Column Name | Description |\n",
    "|------------- |-------------|\n",
    "| `PassengerId` | A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always. |\n",
    "| `Transported` | Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno\n",
    "from collections import Counter\n",
    "\n",
    "# Data visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data - to pandas dataframes\n",
    "test_df = pd.read_csv('./inputs/test.csv')\n",
    "test_idx = test_df['PassengerId']\n",
    "train_df = pd.read_csv('./inputs/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to define logic for empty values\n",
    "\n",
    "One of the most complicated areas is figuring out how to impute empty values. I did figure some of this out but this post was helpful in filling some gaps https://www.kaggle.com/code/jacobsultan/how-to-impute-nearly-every-cabin-correctly\n",
    "\n",
    "We will define that logic here:\n",
    "\n",
    "1. **Cryosleep**\n",
    "    - False if money is spent\n",
    "2. **CabinSide** \n",
    "    - Group is always on the same side of the ship\n",
    "3. **HomePlanet**\n",
    "    - Group Members Share the Same Home Planet: If two passengers are in the same group, they originate from the same home planet. (Appendix A.2)\n",
    "    - Shared Last Names Indicate Same Home Planet: Passengers sharing a last name are from the same home planet.\n",
    "4. **Spending**\n",
    "    - 0 if under 12 \n",
    "5. **CabinRoom**\n",
    "    - can only share a room if in same group\n",
    "6. **CabinDeck**\n",
    "    - Mars: Decks 'D', 'E', or 'F'\n",
    "    - Earth: Decks 'E', 'F', or 'G'\n",
    "    - Europa: Decks 'A', 'B', 'C', 'D', 'E', or 'T'\n",
    "\n",
    "Now we can validate and define functions to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define spend features\n",
    "spend_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_cryosleep(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    UnknownCryoSpender = (df[\"CryoSleep\"].isnull() | df[\"CryoSleep\"].isna()) & (df['TotalSpend'] > 0)\n",
    "    df.loc[UnknownCryoSpender, 'CryoSleep'] = False\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code does not work as when you use `fillna` with `inplace=True` on a DataFrame slice, it doesn't actually modify the original DataFrame. \n",
    "# This is because DataFrame slicing returns a copy, not a view, and `fillna` modifies this copy, not the original DataFrame.\n",
    "\n",
    "# def asleep_or_young(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     df[(df['ShoppingMall'].isna()) & (df['Age'] < 13)].fillna(0, inplace=True)\n",
    "#     return df\n",
    "\n",
    "# In this fixed code, `df.loc[condition, 'ShoppingMall'].fillna(0)` returns a new Series with the missing values in 'ShoppingMall' filled. \n",
    "# This Series is then assigned back to the 'ShoppingMall' column of the original DataFrame, effectively modifying the original DataFrame.\n",
    "def asleep_or_young(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for feature in spend_features:\n",
    "        # young_condition = (df[feature].isna()) & (df['Age'] < 13)\n",
    "        # df.loc[young_condition, feature] = df.loc[young_condition, feature].fillna(0)\n",
    "        # asleep_condition = (df[feature].isna()) & (df['CryoSleep'] == True)\n",
    "        # df.loc[asleep_condition, feature] = df.loc[asleep_condition, feature].fillna(0)\n",
    "        condition = ((df[feature].isna()) & (df['Age'] < 13)) | ((df[feature].isna()) & (df['CryoSleep'] == True))\n",
    "        df.loc[condition, feature] = df.loc[condition, feature].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we loop through all the groups and if there is a CabinSide missing, we fill it with the mode of the group\n",
    "def fill_missing_side(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Step 1: Find the mode of 'CabinSide' for each 'Group'\n",
    "    mode_per_group = df.groupby('Group')['CabinSide'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
    "\n",
    "    # Step 2: Replace NaN values in 'CabinSide' with the mode\n",
    "    df['CabinSide'] = df['CabinSide'].fillna(mode_per_group)\n",
    "\n",
    "    # Step 3: Return the modified DataFrame\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HomePlanet\n",
    "#    - Group Members Share the Same Home Planet: If two passengers are in the same group, they originate from the same home planet. (Appendix A.2)\n",
    "def fill_missing_home_planet_group(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Step 1: Find the mode of 'HomePlanet' for each 'Group'\n",
    "    mode_per_group = df.groupby('Group')['HomePlanet'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
    "\n",
    "    # Step 2: Replace NaN values in 'HomePlanet' with the mode\n",
    "    df['HomePlanet'] = df['HomePlanet'].fillna(mode_per_group)\n",
    "\n",
    "    # Step 3: Return the modified DataFrame\n",
    "    return df\n",
    "\n",
    "#    - Shared Last Names Indicate Same Home Planet: Passengers sharing a last name are from the same home planet.\n",
    "def fill_missing_home_planet_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Step 1: Find the mode of 'HomePlanet' for each 'Group'\n",
    "    mode_per_group = df.groupby('NameSecond')['HomePlanet'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
    "\n",
    "    # Step 2: Replace NaN values in 'HomePlanet' with the mode\n",
    "    df['HomePlanet'] = df['HomePlanet'].fillna(mode_per_group)\n",
    "\n",
    "    # Step 3: Return the modified DataFrame\n",
    "    return df\n",
    "\n",
    "def fill_missing_home_planet(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = fill_missing_home_planet_group(df)\n",
    "    df = fill_missing_home_planet_name(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_missing_vip(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # If HomePlanet is Earth set VIP to False\n",
    "    df.loc[df['HomePlanet'] == 'Earth', 'VIP'] = False\n",
    "\n",
    "    # if CabinDeck is T then VIP False\n",
    "    df.loc[df['CabinDeck'] == 'T', 'VIP'] = False\n",
    "\n",
    "    # Europa VIP have Age >= 25, so VIP FALSE if Europa and Age under 25\n",
    "    df.loc[(df['HomePlanet'] == 'Europa') & (df['Age'] < 25), 'VIP'] = False\n",
    "\n",
    "    # Mars VIP have Age >= 18 and no CryoSleep and never goes to \"55 Cancri e\"\n",
    "    condition = (df['HomePlanet'] == 'Mars') & (df['Age'] < 18) & (df['CryoSleep'] == False) & (df['Destination'] != '55CancriE')\n",
    "    df.loc[condition, 'VIP'] = False\n",
    "\n",
    "    # extract a series of HomePlanet and NameFirst\n",
    "    # fill missing HomePlanet based on NameFirst series\n",
    "    planet_per_name = df.groupby('NameFirst')['HomePlanet'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
    "    df['HomePlanet'] = df['HomePlanet'].fillna(planet_per_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to apply pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_empty_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = empty_cryosleep(df)\n",
    "    df = asleep_or_young(df)\n",
    "    df = fill_missing_side(df)\n",
    "    df = fill_missing_home_planet(df)\n",
    "    df = fill_in_missing_vip(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_and_encoding(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Split out components of the Cabin column\n",
    "    df[[\"CabinDeck\", \"CabinRoom\", \"CabinSide\"]] = df[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "    df['CabinRoom'] = df['CabinRoom'].astype('Int64')\n",
    "\n",
    "    # Calculate Total Spend\n",
    "    df['TotalSpend'] = df[spend_features].sum(axis=1)\n",
    "   \n",
    "    # Extract the group and group Size\n",
    "    df['Group'] = df['PassengerId'].map(lambda x: x.split('_')[0])\n",
    "    df['GroupSize'] = df['Group'].map(df['Group'].value_counts())\n",
    "\n",
    "    # Split the name into first name and last name\n",
    "    df[[\"NameFirst\", \"NameSecond\"]] = df[\"Name\"].str.split(\" \", expand=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-process the data - fill missing values, encode categorical variables, scale the data, feature engineering\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = feature_engineering(df)\n",
    "    df = handle_empty_values(df)\n",
    "    df = scaling_and_encoding(df)\n",
    "    df = df.drop(columns=['Name', 'Cabin'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into features and target\n",
    "\n",
    "# split off the label\n",
    "y = train_df.pop('Transported')\n",
    "\n",
    "# split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>5363_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>F/1102/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>37.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Crowk Apeau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>6324_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G/1025/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Murie Hinetthews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1053_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/199/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>Rald Colleruces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>3128_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/512/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>62.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>Heila Gordond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>2385_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>F/461/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>23.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jacats Pité</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "5020     5363_01       Mars      True  F/1102/P    TRAPPIST-1e  37.0  False   \n",
       "5967     6324_02      Earth       NaN  G/1025/S    55 Cancri e  44.0  False   \n",
       "991      1053_01      Earth     False   F/199/S  PSO J318.5-22  27.0  False   \n",
       "2894     3128_01      Earth     False   G/512/P    55 Cancri e  15.0  False   \n",
       "2228     2385_01       Mars     False   F/461/S    TRAPPIST-1e  23.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "5020          0.0        0.0           0.0     0.0     0.0       Crowk Apeau  \n",
       "5967          0.0        0.0           0.0     0.0     0.0  Murie Hinetthews  \n",
       "991         182.0        0.0           0.0     0.0   376.0   Rald Colleruces  \n",
       "2894         62.0       57.0        2646.0  1104.0   312.0     Heila Gordond  \n",
       "2228       1773.0        0.0          78.0     0.0     3.0       Jacats Pité  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Look at data before preprocessing\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Train Missing  Test Missing\n",
      "VIP                     167            93\n",
      "ShoppingMall            164            98\n",
      "CryoSleep               160            93\n",
      "HomePlanet              150            87\n",
      "Cabin                   145           100\n",
      "Name                    145            94\n",
      "Spa                     144           101\n",
      "RoomService             141            82\n",
      "VRDeck                  139            80\n",
      "Destination             137            92\n",
      "FoodCourt               137           106\n",
      "Age                     135            91\n",
      "PassengerId               0             0\n"
     ]
    }
   ],
   "source": [
    "# extract the indexes of the rows with nan values in the training set to check later\n",
    "nan_rows = X_train[X_train.isnull().any(axis=1)].index\n",
    "\n",
    "## Print any missing data before processing\n",
    "missing_data = pd.DataFrame({\n",
    "    'Train Missing': X_train.isnull().sum().astype(int),\n",
    "    'Test Missing': test_df.isnull().sum().astype(int),\n",
    "}).sort_values(by='Train Missing', ascending=False)\n",
    "\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "X_val = preprocess_data(X_val)\n",
    "test_df = preprocess_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinRoom</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>TotalSpend</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>NameFirst</th>\n",
       "      <th>NameSecond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>5363_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>37.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1102</td>\n",
       "      <td>P</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5363</td>\n",
       "      <td>1</td>\n",
       "      <td>Crowk</td>\n",
       "      <td>Apeau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>6324_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>G</td>\n",
       "      <td>1025</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6324</td>\n",
       "      <td>3</td>\n",
       "      <td>Murie</td>\n",
       "      <td>Hinetthews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1053_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>F</td>\n",
       "      <td>199</td>\n",
       "      <td>S</td>\n",
       "      <td>558.0</td>\n",
       "      <td>1053</td>\n",
       "      <td>1</td>\n",
       "      <td>Rald</td>\n",
       "      <td>Colleruces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>3128_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>62.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>G</td>\n",
       "      <td>512</td>\n",
       "      <td>P</td>\n",
       "      <td>4181.0</td>\n",
       "      <td>3128</td>\n",
       "      <td>1</td>\n",
       "      <td>Heila</td>\n",
       "      <td>Gordond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>2385_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>23.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>461</td>\n",
       "      <td>S</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>2385</td>\n",
       "      <td>1</td>\n",
       "      <td>Jacats</td>\n",
       "      <td>Pité</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep    Destination   Age    VIP  \\\n",
       "5020     5363_01       Mars      True    TRAPPIST-1e  37.0  False   \n",
       "5967     6324_02      Earth       NaN    55 Cancri e  44.0  False   \n",
       "991      1053_01      Earth     False  PSO J318.5-22  27.0  False   \n",
       "2894     3128_01      Earth     False    55 Cancri e  15.0  False   \n",
       "2228     2385_01       Mars     False    TRAPPIST-1e  23.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck CabinDeck  \\\n",
       "5020          0.0        0.0           0.0     0.0     0.0         F   \n",
       "5967          0.0        0.0           0.0     0.0     0.0         G   \n",
       "991         182.0        0.0           0.0     0.0   376.0         F   \n",
       "2894         62.0       57.0        2646.0  1104.0   312.0         G   \n",
       "2228       1773.0        0.0          78.0     0.0     3.0         F   \n",
       "\n",
       "      CabinRoom CabinSide  TotalSpend Group  GroupSize NameFirst  NameSecond  \n",
       "5020       1102         P         0.0  5363          1     Crowk       Apeau  \n",
       "5967       1025         S         0.0  6324          3     Murie  Hinetthews  \n",
       "991         199         S       558.0  1053          1      Rald  Colleruces  \n",
       "2894        512         P      4181.0  3128          1     Heila     Gordond  \n",
       "2228        461         S      1854.0  2385          1    Jacats        Pité  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DEBUGGING - Look at data after  preprocessing\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinRoom</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>TotalSpend</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>NameFirst</th>\n",
       "      <th>NameSecond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>6324_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>G</td>\n",
       "      <td>1025</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6324</td>\n",
       "      <td>3</td>\n",
       "      <td>Murie</td>\n",
       "      <td>Hinetthews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>1964_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>63.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>869.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>C</td>\n",
       "      <td>74</td>\n",
       "      <td>S</td>\n",
       "      <td>4622.0</td>\n",
       "      <td>1964</td>\n",
       "      <td>1</td>\n",
       "      <td>Altara</td>\n",
       "      <td>Righturter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>6921_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>255</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6921</td>\n",
       "      <td>5</td>\n",
       "      <td>Eleron</td>\n",
       "      <td>Fordulgaug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333</th>\n",
       "      <td>7848_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>29.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>7848</td>\n",
       "      <td>2</td>\n",
       "      <td>Neypus</td>\n",
       "      <td>Pine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0794_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>144</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0794</td>\n",
       "      <td>2</td>\n",
       "      <td>Nakes</td>\n",
       "      <td>Dutte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep  Destination   Age    VIP  RoomService  \\\n",
       "5967     6324_02      Earth       NaN  55 Cancri e  44.0  False          0.0   \n",
       "1839     1964_01     Europa     False  TRAPPIST-1e  63.0  False          NaN   \n",
       "6558     6921_02     Europa      True  55 Cancri e  24.0  False          0.0   \n",
       "7333     7848_01       Mars     False  TRAPPIST-1e  29.0  False       1052.0   \n",
       "756      0794_01       Mars       NaN  55 Cancri e  19.0  False          0.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall    Spa  VRDeck CabinDeck  CabinRoom CabinSide  \\\n",
       "5967        0.0           0.0    0.0     0.0         G       1025         S   \n",
       "1839      869.0           1.0  375.0  3377.0         C         74         S   \n",
       "6558        0.0           0.0    0.0     0.0         C        255         S   \n",
       "7333        0.0         635.0    0.0     0.0       NaN       <NA>         S   \n",
       "756         0.0           0.0    0.0     0.0         F        144         S   \n",
       "\n",
       "      TotalSpend Group  GroupSize NameFirst  NameSecond  \n",
       "5967         0.0  6324          3     Murie  Hinetthews  \n",
       "1839      4622.0  1964          1    Altara  Righturter  \n",
       "6558         0.0  6921          5    Eleron  Fordulgaug  \n",
       "7333      1687.0  7848          2    Neypus        Pine  \n",
       "756          0.0  0794          2     Nakes       Dutte  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DEBUGGING - Look at data with nan values\n",
    "nan_rows_df = X_train.loc[nan_rows]\n",
    "nan_rows_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Train Missing  Test Missing\n",
      "NameSecond              145            94\n",
      "CabinDeck               145           100\n",
      "NameFirst               145            94\n",
      "CabinRoom               145           100\n",
      "Destination             137            92\n",
      "Age                     135            91\n",
      "Spa                      97            52\n",
      "CabinSide                87            63\n",
      "RoomService              84            55\n",
      "ShoppingMall             83            60\n",
      "FoodCourt                80            65\n",
      "VRDeck                   76            43\n",
      "CryoSleep                69            38\n",
      "VIP                      67            47\n",
      "HomePlanet                3             7\n",
      "TotalSpend                0             0\n",
      "Group                     0             0\n",
      "GroupSize                 0             0\n",
      "PassengerId               0             0\n"
     ]
    }
   ],
   "source": [
    "## Print any missing data\n",
    "missing_data = pd.DataFrame({\n",
    "    'Train Missing': X_train.isnull().sum().astype(int),\n",
    "    'Test Missing': test_df.isnull().sum().astype(int),\n",
    "}).sort_values(by='Train Missing', ascending=False)\n",
    "\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "\n",
    "### Instantiate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'Perceptron': Perceptron(),\n",
    "    'SVC': SVC(),\n",
    "    'KNN5': KNeighborsClassifier(n_neighbors = 5),\n",
    "    'KNN8': KNeighborsClassifier(n_neighbors = 8),\n",
    "    'KNN10': KNeighborsClassifier(n_neighbors = 10),\n",
    "    'KNN15': KNeighborsClassifier(n_neighbors = 15),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'Gaussian': GaussianNB(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'LinearSvc': LinearSVC(),\n",
    "    'SGDClassifier': SGDClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'LightGBM': LGBMClassifier(verbose=-0),\n",
    "    'SVC_linear': SVC(kernel='linear'),\n",
    "    'SVC_poly': SVC(kernel='poly'),\n",
    "    'SVC_sigmoid': SVC(kernel='sigmoid'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to score the model\n",
    "def score_model(classifier, X_train, X_val, y_train, y_val):\n",
    "    # Fit the model\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test data\n",
    "    y_pred = classifier.predict(X_val)\n",
    "\n",
    "    # Create a confusion matrix\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    return { \n",
    "            'confusion_matrix': cm,\n",
    "            'TP': cm[0][0],\n",
    "            'FP': cm[0][1],\n",
    "            'FN': cm[1][0],\n",
    "            'TN': cm[1][1],\n",
    "            'accuracy': accuracy_score(y_val, y_pred),\n",
    "            'kfold-cv': cross_val_score(classifier, X_train, y_train, cv = 10).mean(),\n",
    "            'f1': f1_score(y_val, y_pred)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Mars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, classifier \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 4\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m \u001b[43mscore_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[167], line 4\u001b[0m, in \u001b[0;36mscore_model\u001b[0;34m(classifier, X_train, X_val, y_train, y_val)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_model\u001b[39m(classifier, X_train, X_val, y_train, y_val):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Predict the test data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1208\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1206\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1208\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:836\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    835\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 836\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    838\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/pandas/core/generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/source/edoatley/ml/.venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Mars'"
     ]
    }
   ],
   "source": [
    "## Loop through the classifiers and score them\n",
    "results = {}\n",
    "for name, classifier in classifiers.items():\n",
    "    results[name] = score_model(classifier, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to a dataframe and sort by accuracy\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.sort_values(by='accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
