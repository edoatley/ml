{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Set up your environment.\n",
    "\n",
    "This is the tutorial defined [here](https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn#step-1). To get started we set up our environment:\n",
    "\n",
    "1. Create `venv` (or do so in vs code):\n",
    "\n",
    "```bash\n",
    "python3 -m venv .venv\n",
    "```\n",
    "\n",
    "2. Activate `venv` (path is relative to this file):\n",
    "\n",
    "```bash\n",
    "source ../../.venv/bin/activate \n",
    "```\n",
    "\n",
    "3. Check python & pip are there and using venv ones:\n",
    "\n",
    "```bash\n",
    "which python \n",
    "which pip \n",
    "```\n",
    "\n",
    "4. Install packages:\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn\n",
    "pip install numpy \n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "5. Freeze packages and write `requirements.txt`:\n",
    "\n",
    "```bash\n",
    "pip freeze > requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 2: Import libraries and modules.\n",
    "\n",
    "# import numpy, which provides support for more efficient numerical computation:\n",
    "import numpy as np\n",
    "\n",
    "# Pandas, a convenient library that supports dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# model_selection - contains many utilities that will help us choose between models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# preprocessing module. This contains utilities for scaling, transforming, and wrangling data.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# import the families of models we’ll need - random forest family\n",
    "# For the scope of this tutorial, we’ll only focus on training a random forest and tuning its parameters. \n",
    "# We’ll have another detailed tutorial for how to choose between model families.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# importing the tools to help us perform cross-validation.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#some metrics we can use to evaluate our model performance later.\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# way to persist our model for future use - Joblib is an alternative to Python’s pickle package, \n",
    "# and we’ll use it because it’s more efficient for storing large numpy arrays.\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "#@title Step 3: Load red wine data.\n",
    "\n",
    "# convenient tool we’ll use today is the read_csv() function. Using this function, we can load any CSV file, even from a remote URL\n",
    "#dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "dataset_url='wine-quality.csv' # using this as actual URL gave self signed SSL error\n",
    "data = pd.read_csv(dataset_url, sep=';') # data is using ; to separate data (not comma default)\n",
    "\n",
    "# Now let’s take a look at the first 5 rows of data:\n",
    "print( data.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 4: Split data into training and test sets.\n",
    "\n",
    "# First, let’s separate our target (y) features from our input (X) features:\n",
    "y = data.quality\n",
    "X = data.drop('quality', axis=1)\n",
    "\n",
    "# This allows us to take advantage of Scikit-Learn’s useful train_test_split function:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
